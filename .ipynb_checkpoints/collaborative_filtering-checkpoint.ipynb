{
 "metadata": {
  "name": "",
  "signature": "sha256:afa71fede44ea5cc37258fa62ae3d86fbe4f1f7d3d53df87f2cda9eb72fe0fbb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction To Collaborative Filtering\n",
      "\n",
      "We start with a list of users and items. There can be **explicit** opinion such as the rating score by the user for an item, or **implicit** which we can infer from the user's behavior such as past buying behavior, shopping cart analysis or videos watched.\n",
      "\n",
      "Generally, it is usually much better off going with implicit data. Implicit data is easier to get since we do no need the involvement of the user. Explicit opinion is much harder to get and to get to a meaningful scale requires a lot of time and effort. The data is usually very noisy. Users rate very differently, a score of 4 can mean different things for different users. Some users also do aspirational rating, or they only rate when it's good.\n",
      "\n",
      "There are many companies such as YouTube which changed their rating system from 1-5 stars to thumbs up or down.\n",
      "\n",
      "# Basic Approach to Collaborative Filtering\n",
      "- Identify the target user for which the CF prediction task will be performed. \n",
      "- A metric for measuring similarity between users. \n",
      "- A method for selecting a subset of neighbors\n",
      "- A method for predicting a rating for items not rated by the target user.\n",
      "\n",
      "# The Intuition Behind Collaborative Filtering\n",
      "\n",
      "If we need to recommend an item to a user, we look at 5 other users which are most similar to the user. Ask the 5 other users what they like, and recommend the item to the target user.\n",
      "\n",
      "In practice, we almost never implement given all the limitations.\n",
      "\n",
      "For collaborative filtering, we looking at the interaction between the users and items, look for similarity in the users or the items, use the average of the neighbors to do the recommendation.\n",
      "\n",
      "# The Pros and Cons\n",
      "\n",
      "**Pros**:\n",
      "We require minimal domain knowledge of the item. There is no need to know a lot about the items. It can be applied across various items. The method can be used independently. Most of the time, it produces good enough results.\n",
      "\n",
      "**Cons**:\n",
      "We need a lot of data. It is easier to say do CF, however we will need items and users. Unless we have items and data on the users, otherwise we will not be able to bootstrap the system for CF. We often run into the tricky issue of sparsity. If a company has a large catalog of items, we will require the users to buy the small product over and over again. It is often hard to find users who have bought the exact same product.\n",
      "\n",
      "# What is the difference between personalized vs non-personalized CF?\n",
      "\n",
      "If we do not have any data on the user, it probably best to recommend the most popular items. This non-personalized collaborative-based recommendation can be generated by averaging the recommendations of all the users. It is often a good idea to start with the most popular items, which will be the baseline we are operating from. \n",
      "\n",
      "Personalized CF recommendations are based on ratings which are expressed by similar users. If we are building a personalized recommendation and it should perform better than non-personalized recommendations. Otherwise, there is simply no point to spend the effort to do personalized recommendations.\n",
      "\n",
      "It is fairly easy to produce a reasonable baseline recommendation (such as the average most popular) but extremely difficult to improve them. However, small improvements often translate to large revenue and profit. Every improvement can be measured in thousands or millions of dollars."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# User-based Collaborative Filtering\n",
      "\n",
      "<img src=\"./images/ubcf.png\">\n",
      "\n",
      "The weights is computed based on the idea of similarity. The more similar user, the more weight is assigned. The similarity function such as Pearson correlation, is first used to find the nearest neighbor and then used it as a weighted average to produce the predicted rating for the target user.\n",
      "\n",
      "# Challenges of Collaborative Filtering\n",
      "\n",
      "The biggest challenge is the sparsity. Typically, there's a large product sets and user ratings only forma  small percentage of them. If the sparsity is under 1%, it is going to a challenge to try to find those neighborhood. It will be a challenge to make predictions given the sparsity. As it becomes bigger, we will also face the challenge of scalability where it will become more and more computationally expensive. \n",
      "\n",
      "Generally rule of thumb is when we have the number of users comparable to one-tenth size of the product catalogue, we can probably get started.\n",
      "\n",
      "One suggested solution is the usage of latent models to capture the similarity between users and items in a reduced dimensional space. The idea is to compact the sparse matrix into a fully dense matrix. Instead of the matrix of representing items which is going to be a sparse space, we can recommend dimensions in our space such as categories which has a much smaller and dense matrix.\n",
      "\n",
      "Some methods of dimensionality reduction includes matrix factorization, clustering, and PCA. Do some clustering to get groups of users and only do similarity calculation on the groups.\n",
      "\n",
      "1. **Cold Start**: There needs to have enough users already in the system to find a match. New items need to have enough ratings.\n",
      "* **Popularity Bias**: Hard to recommend items to users with unique tastes. We often only recommend popular items. The items at the long tail do not have much data.\n",
      "\n",
      "# Item-based Collaborative Filtering\n",
      "\n",
      "The key concepts is similar to user-based CF. We consider the items very similar if the same subset of users like those same items. Compute the prediction by taking the weighted average of the target user's ratings on most similar items.\n",
      "\n",
      "<img src=\"./images/ibcf.png\">\n",
      "<img src=\"./images/ibcf2.png\">\n",
      "<img src=\"./images/ibcf3.png\">\n",
      "<img src=\"./images/ibcf4.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model-based CF Algorithms\n",
      "\n",
      "- Memory based: Use the entire user-item database to generate the prediction using statistical techniques to find the nearest neighbor method)\n",
      "- Model based: First develop a model and use the model to make predictions. Examples:\n",
      "    - Clustering\n",
      "    - Rule-based (Association Rules)\n",
      "    - Classifers\n",
      "    - Regression\n",
      "    - LDA, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 22pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x10382c690>"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}