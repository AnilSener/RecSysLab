{
 "metadata": {
  "name": "",
  "signature": "sha256:f0431c3deac719fad42f9472e616d6dd2491ff65d104a35c7af5c34e720e1f76"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Background\n",
      "\n",
      "We have learned many things from the Netflix prize about model-based collaborative filtering. During the competition, there were many research and experimentation on what model-based CF could do. The top 2 algorithms that came out of the competition are SVD and RBM, measured by RMSE. The blend method of the 2 algorithms gave a even lower RMSE, improving the results of the prediction. This was then used as part of Netflix rating prediction in production. \n",
      "\n",
      "We will look at Singular Value Decomposition in detail in this essay.\n",
      "\n",
      "# Introduction To Singular Value Decomposition (SVD)\n",
      "\n",
      "The main basic idea is we have a original sparse matrix which is full of zeros. We will decompose it into fewer dimensions in order to make it less sparse. The method to do the decomposition/factorization is to use SVD/MF. \n",
      "\n",
      "The method to doing this with SVD is to first perform mean normalization and feature scaling on data X with n-dimensions. Compute a covariance matrix Sigma for X. Then compute SVD on sigma to get its eigenvectors.\n",
      "\n",
      "<img src=\"./images/svd.png\">\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# User-based Collaborative Filtering\n",
      "\n",
      "<img src=\"./images/ubcf.png\">\n",
      "\n",
      "The weights is computed based on the idea of similarity. The more similar user, the more weight is assigned. The similarity function such as Pearson correlation, is first used to find the nearest neighbor and then used it as a weighted average to produce the predicted rating for the target user.\n",
      "\n",
      "# Challenges of Collaborative Filtering\n",
      "\n",
      "The biggest challenge is the sparsity. Typically, there's a large product sets and user ratings only forma  small percentage of them. If the sparsity is under 1%, it is going to a challenge to try to find those neighborhood. It will be a challenge to make predictions given the sparsity. As it becomes bigger, we will also face the challenge of scalability where it will become more and more computationally expensive. \n",
      "\n",
      "Generally rule of thumb is when we have the number of users comparable to one-tenth size of the product catalogue, we can probably get started.\n",
      "\n",
      "One suggested solution is the usage of latent models to capture the similarity between users and items in a reduced dimensional space. The idea is to compact the sparse matrix into a fully dense matrix. Instead of the matrix of representing items which is going to be a sparse space, we can recommend dimensions in our space such as categories which has a much smaller and dense matrix.\n",
      "\n",
      "Some methods of dimensionality reduction includes matrix factorization, clustering, and PCA. Do some clustering to get groups of users and only do similarity calculation on the groups.\n",
      "\n",
      "1. **Cold Start**: There needs to have enough users already in the system to find a match. New items need to have enough ratings.\n",
      "* **Popularity Bias**: Hard to recommend items to users with unique tastes. We often only recommend popular items. The items at the long tail do not have much data.\n",
      "\n",
      "# Item-based Collaborative Filtering\n",
      "\n",
      "The key concepts is similar to user-based CF. We consider the items very similar if the same subset of users like those same items. Compute the prediction by taking the weighted average of the target user's ratings on most similar items.\n",
      "\n",
      "<img src=\"./images/ibcf.png\">\n",
      "<img src=\"./images/ibcf2.png\">\n",
      "<img src=\"./images/ibcf3.png\">\n",
      "<img src=\"./images/ibcf4.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model-based CF Algorithms\n",
      "\n",
      "- Memory based: Use the entire user-item database to generate the prediction using statistical techniques to find the nearest neighbor method)\n",
      "- Model based: First develop a model and use the model to make predictions. Examples:\n",
      "    - Clustering\n",
      "    - Rule-based (Association Rules)\n",
      "    - Classifers\n",
      "    - Regression\n",
      "    - LDA, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
        "    }\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        font-weight: bold;\n",
        "        font-style: oblique;\n",
        "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 22pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x103820d50>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}